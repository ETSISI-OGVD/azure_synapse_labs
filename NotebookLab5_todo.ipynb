{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Explore and analyze data in Synapse with Spark SQL - Simple analysis by using data from a Data Lake (Analyze NYC Taxi data with a Spark pool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Place sample data into the primary storage account\r\n",
        "\r\n",
        "We are going to use a small sample dataset of NYC Taxi Cab data. We begin by placing it in the primary storage account (i.e. the datalake) you created for the workspace.\r\n",
        "\r\n",
        "- Download the [NYC Taxi - green trip dataset](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) to your computer. Navigate to the original dataset location from the above link, choose a specific year and month and download the Green taxi trip records in Parquet format.\r\n",
        "- Rename the downloaded file to NYCTripSmall.parquet.\r\n",
        "- In Synapse Studio, navigate to the Data Hub. Select Linked.\r\n",
        "- Under the category Azure Data Lake Storage Gen2 you'll see an item with the name of your workspace (Primary - the name of your datalake account).\r\n",
        "- Under your workspace you'll see a container with the name of your datalake storage file system (Primary). Select this container\r\n",
        "- In the menu, select Upload and select the NYCTripSmall.parquet file you downloaded.\r\n",
        "\r\n",
        "Once the parquet file is uploaded it is available through two equivalent URIs that you can see in the Properties of the parquet file (see the ABFSS Path)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Load the NYC Taxi data into a Spark dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Print the schema of the dataframe run a cell with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Load the NYC Taxi data into the Spark nyctaxi database\r\n",
        "\r\n",
        "Data is available via the dataframe named df. Load it into a Spark database named nyctaxi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Analyze the NYC Taxi data using Spark\r\n",
        "\r\n",
        "Show the NYC Taxi data we loaded into the nyctaxi Spark database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "By number of passengers shows the average distance of the trip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Save the notebook and end the Spark session\r\n",
        "\r\n",
        "Now that you’ve finished working with the data, you can publish the notebook with a meaningful name and end the Spark session.\r\n",
        "\r\n",
        "- In the notebook menu bar, use the Properites icon to view the notebook settings.\r\n",
        "- Set the Name of the notebook and then close the settings pane.\r\n",
        "- Below the notebook menu (right corner), select Stop session icon to end the Spark session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Clean up resources\r\n",
        "In this exercise, you’ve learned how to use Spark to work with data in Azure Synapse.\r\n",
        "\r\n",
        "If you’ve finished exploring your lakehouse, you can delete the workspace you created for this exercise."
      ]
    }
  ],
  "metadata": {
    "description": "Explore and analyze data in Synapse with a serverless Apache Spark pool\nhttps://learn.microsoft.com/en-us/azure/synapse-analytics/get-started-analyze-spark",
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}